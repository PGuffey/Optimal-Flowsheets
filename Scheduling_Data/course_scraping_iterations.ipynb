{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to slu_courses.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import mechanize\n",
    "\n",
    "# Initialize mechanize browser\n",
    "br = mechanize.Browser()\n",
    "br.set_handle_equiv(True)\n",
    "br.set_handle_redirect(True)\n",
    "br.set_handle_referer(True)\n",
    "br.set_handle_robots(False)\n",
    "\n",
    "# Open a specific course page (Computer Science in this example)\n",
    "link = \"https://catalog.slu.edu/courses-az/csci/\"\n",
    "br.open(link)\n",
    "html = br.response().read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all course blocks\n",
    "course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "# Initialize list to store course data\n",
    "courses_data = []\n",
    "\n",
    "# Extract data from each course block\n",
    "for block in course_blocks:\n",
    "    course_title = block.find(\"p\", class_=\"courseblocktitle noindent\")\n",
    "    credits = block.find(\"p\", class_=\"courseblockextra noindent\")\n",
    "    prerequisites = block.find(\"p\", class_=\"courseblockprereq noindent\")\n",
    "\n",
    "    courses_data.append({\n",
    "        'Course Title': course_title.text.strip() if course_title else 'NaN',\n",
    "        'Credits': credits.text.strip() if credits else 'NaN',\n",
    "        'Prerequisites': prerequisites.text.strip() if prerequisites else 'NaN'\n",
    "    })\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "courses_df = pd.DataFrame(courses_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"slu_courses.csv\"\n",
    "courses_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to slu_courses2.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import mechanize\n",
    "\n",
    "# Initialize mechanize browser\n",
    "br = mechanize.Browser()\n",
    "br.set_handle_equiv(True)\n",
    "br.set_handle_redirect(True)\n",
    "br.set_handle_referer(True)\n",
    "br.set_handle_robots(False)\n",
    "\n",
    "# Open a specific course page (Computer Science in this example)\n",
    "link = \"https://catalog.slu.edu/courses-az/csci/\"\n",
    "br.open(link)\n",
    "html = br.response().read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all course blocks\n",
    "course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "# Initialize list to store course data\n",
    "courses_data = []\n",
    "\n",
    "# Extract data from each course block\n",
    "for block in course_blocks:\n",
    "    course_title = block.find(\"p\", class_=\"courseblocktitle noindent\")\n",
    "    credits = block.find(\"p\", class_=\"courseblockextra noindent\")\n",
    "    \n",
    "    # Find prerequisite information\n",
    "    prerequisites = \"NaN\"\n",
    "    for extra in block.find_all(\"p\", class_=\"courseblockextra noindent\"):\n",
    "        if extra.find(\"strong\") and \"Prerequisite(s):\" in extra.find(\"strong\").text:\n",
    "            prereq_links = extra.find_all(\"a\")\n",
    "            prereqs = [link.text.strip() for link in prereq_links]\n",
    "            prerequisites = ', '.join(prereqs)\n",
    "            break\n",
    "\n",
    "    courses_data.append({\n",
    "        'Course Title': course_title.text.strip() if course_title else 'NaN',\n",
    "        'Credits': credits.text.strip() if credits else 'NaN',\n",
    "        'Prerequisites': prerequisites\n",
    "    })\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "courses_df = pd.DataFrame(courses_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"slu_courses2.csv\"\n",
    "courses_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to slu_courses.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import mechanize\n",
    "\n",
    "# Initialize mechanize browser\n",
    "br = mechanize.Browser()\n",
    "br.set_handle_equiv(True)\n",
    "br.set_handle_redirect(True)\n",
    "br.set_handle_referer(True)\n",
    "br.set_handle_robots(False)\n",
    "\n",
    "# Open a specific course page (Computer Science in this example)\n",
    "link = \"https://catalog.slu.edu/courses-az/csci/\"\n",
    "br.open(link)\n",
    "html = br.response().read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Find all course blocks\n",
    "course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "# Initialize list to store course data\n",
    "courses_data = []\n",
    "\n",
    "# Extract data from each course block\n",
    "for block in course_blocks:\n",
    "    course_title = block.find(\"p\", class_=\"courseblocktitle noindent\")\n",
    "    credits = block.find(\"p\", class_=\"courseblockextra noindent\")\n",
    "    \n",
    "    # Find prerequisite information\n",
    "    prerequisites = \"NaN\"\n",
    "    concurrent_enrollment = \"NaN\"\n",
    "    for extra in block.find_all(\"p\", class_=\"courseblockextra noindent\"):\n",
    "        if extra.find(\"strong\") and \"Prerequisite(s):\" in extra.find(\"strong\").text:\n",
    "            prereq_links = extra.find_all(\"a\")\n",
    "            prereqs = [link.text.strip() for link in prereq_links]\n",
    "            prerequisites = ', '.join(prereqs)\n",
    "            \n",
    "            # Check for concurrent enrollment info\n",
    "            sup_tags = extra.find_all(\"sup\")\n",
    "            for sup in sup_tags:\n",
    "                if \"Concurrent enrollment allowed.\" in sup.next_sibling:\n",
    "                    concurrent_enrollment = \"Concurrent enrollment allowed.\"\n",
    "                    break\n",
    "            break\n",
    "\n",
    "    courses_data.append({\n",
    "        'Course Title': course_title.text.strip() if course_title else 'NaN',\n",
    "        'Credits': credits.text.strip() if credits else 'NaN',\n",
    "        'Prerequisites': prerequisites,\n",
    "        'Concurrent Enrollment': concurrent_enrollment\n",
    "    })\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "courses_df = pd.DataFrame(courses_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"slu_courses.csv\"\n",
    "courses_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import mechanize\n",
    "\n",
    "# Function to scrape course data for a given link\n",
    "def scrape_course_data(major_link):\n",
    "    # Initialize mechanize browser\n",
    "    br = mechanize.Browser()\n",
    "    br.set_handle_equiv(True)\n",
    "    br.set_handle_redirect(True)\n",
    "    br.set_handle_referer(True)\n",
    "    br.set_handle_robots(False)\n",
    "\n",
    "    # Open the course page\n",
    "    base_url = \"https://catalog.slu.edu\"\n",
    "    link = base_url + major_link\n",
    "    br.open(link)\n",
    "    html = br.response().read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Find all course blocks\n",
    "    course_blocks = soup.find_all(\"div\", class_=\"courseblock\")\n",
    "\n",
    "    # Initialize list to store course data\n",
    "    courses_data = []\n",
    "\n",
    "    # Extract data from each course block\n",
    "    for block in course_blocks:\n",
    "        course_title = block.find(\"p\", class_=\"courseblocktitle noindent\")\n",
    "        credits = block.find(\"p\", class_=\"courseblockextra noindent\")\n",
    "        \n",
    "        # Find prerequisite information\n",
    "        prerequisites = \"NaN\"\n",
    "        concurrent_enrollment = \"NaN\"\n",
    "\n",
    "        for extra in block.find_all(\"p\", class_=\"courseblockextra noindent\"):\n",
    "            if extra.find(\"strong\") and \"Prerequisite(s):\" in extra.find(\"strong\").text:\n",
    "                prereq_links = extra.find_all(\"a\")\n",
    "                prereqs = [link.text.strip() for link in prereq_links]\n",
    "                prerequisites = ', '.join(prereqs)\n",
    "                \n",
    "                # Check for concurrent enrollment info\n",
    "                sup_tags = extra.find_all(\"sup\")\n",
    "                for sup in sup_tags:\n",
    "                    if sup.next_sibling and \"Concurrent enrollment allowed.\" in sup.next_sibling:\n",
    "                        concurrent_enrollment = \"Concurrent enrollment allowed.\"\n",
    "                        break\n",
    "                break\n",
    "\n",
    "        courses_data.append({\n",
    "            'Course Title': course_title.text.strip() if course_title else 'NaN',\n",
    "            'Credits': credits.text.strip() if credits else 'NaN',\n",
    "            'Prerequisites': prerequisites,\n",
    "            'Concurrent Enrollment': concurrent_enrollment\n",
    "        })\n",
    "\n",
    "    return courses_data\n",
    "\n",
    "# Read the major links from the file\n",
    "major_links_file = 'major_links.txt'\n",
    "with open(major_links_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize a list to store all courses data\n",
    "all_courses_data = []\n",
    "\n",
    "# Process each major link\n",
    "for line in lines:\n",
    "    major_link, major_name = line.strip().split(', ', 1)\n",
    "    major_courses_data = scrape_course_data(major_link)\n",
    "    \n",
    "    # Add major name to each course entry\n",
    "    for course in major_courses_data:\n",
    "        course['Major'] = major_name\n",
    "    \n",
    "    all_courses_data.extend(major_courses_data)\n",
    "\n",
    "# Convert the combined data to a DataFrame\n",
    "all_courses_df = pd.DataFrame(all_courses_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"all_slu_courses.csv\"\n",
    "all_courses_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
